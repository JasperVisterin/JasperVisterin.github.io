<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Controller Optimization Animations</title>

  <!-- MathJax for LaTeX rendering -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    body {
      font-family: sans-serif;
      margin: 40px;
      max-width: 900px;
    }
    .video-container {
      margin: 20px 0;
    }
    .math {
      margin-top: 20px;
      font-size: 1.2em;
    }
  </style>
</head>
<body>

  <h1>Distributed Delay Controller Optimization</h1>

  <p class="math">
    This website was created to support the Thesis 'Control by Shaping Delay Distribution' by Jasper Visterin. If you are already familiar with the matter, 
    feel free to skip to the animations illustrating a tradeoff between kernel smoothness and closed-loop plant performance, or more concretely, the regularization-spectral abscissa tradeoff.
  </p>

 <p class="math">
    The main concern when doing this is that the kernel \(g(\theta)\) will exhibit extreme oscillations when \( K \) is chosen large. This effect has all kinds of undesired consequences. Hence,
    two approaches have been developed to deal with this. On one hand, there is a Penalty-Based Regularization which uses a Penalty-term \(REG(c)\). This Penalty-term is implemented in the following way:
    $$
   REG(c)=R[g]=\int_{-\tau}^{0}\left(g^{\prime}(\theta)\right)^2 d \theta
   $$
   $$
    \min_{\mathbf{p}} \max \{\operatorname{Re}(\lambda)\} = \min_{\mathbf{p}} \sigma_{\max}
   $$
   The other option is a more heuristic regularization. This heuristic, which is called the Damping Heuristic, has been developed via Chebyshev approximation theory. 
   The intuition used here is that, roughly speaking, for analytic functions that are analytic on a larger domain that these functions have Chebyshev coefficients that decay faster than functions which are analytic on a smaller domain. Assuming reasonable conditions, both functions have coefficients that decay exponentially [1]. 
   Hence, to obtain smooth kernels \(g(\theta)\), this principle can be employed. The Chebyshev coefficients are damped with an exponential factor \( \rho>1 \): 
   $$
   c_k= 
\begin{cases}
\tilde{c}_k& 0\leq k \leq 5 \\
\frac{\tilde{c}_k}{\rho^{k-5}}, & 6 \leq k
\end{cases}    
   $$
   Note that this concept does not directly penalize the global smoothness, but controls the kernel's resolution to avoid overfitting or instability. It acts as a practical damping mechanism during optimization. 
   While \( \rho \) is still a hyperparameter, the concept is simple, interpretable, and rooted in Chebyshev approximation theory. 
 </p>

  <p class="math">
    Furthermore, as regularization is applied, the spectral abscissa will always experience an increase compared to the situation where \(g(\theta)\) is not regularized. 
    It is, in fact, a multi-objective optimization problem where two objectives are optimized at once. 
    In bi-objective optimization, different linear combinations of two convex objective functions, \(J_1(\mathbf{p}) \) and \(J_2(\mathbf{p}) \), trace out the Pareto front. 
    However, for the two objectives \(\sigma_{\max}\) and \(REG(c)\), the complete objective function will be non-convex due to the presence of the spectral abscissa. 
    Hence, this visualization is only valid for a specific local minimum. In non-convex scenarios, one approach to constructing a Pareto front involves identifying a local minimum of the weighted objective for a specific \(\alpha\) value. 
    By systematically varying \(\alpha\) across a predefined grid and solving the optimization problem at each step, this method seeks to observe the evolution of the local minimum, 
    thereby approximating the local Pareto front.
    $$
 \min _{\mathbf{p}} \alpha J_1(\mathbf{p})+(1-\alpha)J_2(\mathbf{p}),\quad\alpha\in[0,1]
$$
Theory showed that constructing such a Pareto front, following the latter described process, can express discontinuous jumps between local minima due to the non-convex nature 
    of the objective [2]. Experiments confirmed that this can indeed happen.
    The purpose of this website is to show how this Pareto Front is formed using the different kinds of regularization. In the case of the Damping Heuristic, one cannot strictly speak about a bi-objective optimization because the damping is implicit, unlike \( REG(c) \).
    However, the visual of the Pareto Front can also be obtained by using damping. As you continue on this website, you will see in the provided animations of
    how the spectral abscissa changes when a regularization parameter like \( \alpha \) or \( \rho \) is changed. 

  </p>
  
  <p class="math">
    The videos below show the evolution of the spectrum as parameters are tuned for the following system:
    $$ P \leftrightarrow  \dot{x}(t) = (1-e^{-1})x(t)+\frac{1}{2}x(t-1)+\frac{e}{2}\,x(t-2)+\frac{e^2}{2} x(t-3) +\int_{-1}^{0}\theta \,x(t+\theta)d\theta  + u\left(t-\frac{1}{32}\right) $$
    For this system, illustrations of both Penalty- as Damping-regularization are given.
  </p>

    <div class="video-container">
    <video width="100%" controls>
      <source src="first_experiment.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>

    <div class="video-container">
    <video width="100%" controls>
      <source src="second_experiment.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>

      <div class="video-container">
    <video width="100%" controls>
      <source src="system_1_alpha_animation.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>

    <p class="math">
    The video below shows the evolution of the spectrum as parameters are tuned for the following system:
    $$ P \leftrightarrow   \dot{x}(t) = \left(1-e^{-1}\right)\begin{bmatrix}
1 & 2 \\
2 & 1 \\
\end{bmatrix}x(t)
+\frac{1}{2}\begin{bmatrix}
1 & 0 \\
0 & 1 \\
\end{bmatrix}x(t-1)+
\frac{e}{2}\begin{bmatrix}
-2 & 1 \\
1 & -2 \\
\end{bmatrix}x(t-2)+ \int_{-1}^{0}\begin{bmatrix}
2e^{\theta} & 0 \\
0 & e^{\theta} \\
\end{bmatrix} x(t+\theta)
 d\theta 
 +
\begin{bmatrix}
1 \\
0 \\
\end{bmatrix}u\left(t-\frac{1}{2}\right)  $$
  </p>

  <div class="video-container">
    <video width="100%" controls>
      <source src="system_2_experiment.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>



   <p class="math">
     Sources: 
   </p>
 <p class="math">
     [1] L. N. Trefethen, Approximation Theory and Approximation Practice, Extended Edition. 1 2019.
   </p>
  <p class="math">
     [2] K. Miettinen, Nonlinear multiobjective optimization. 1 1998.
   </p>
  
</body>
</html>
