<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Controller Optimization Animations</title>

  <!-- MathJax for LaTeX rendering -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    body {
      font-family: sans-serif;
      margin: 40px;
      max-width: 900px;
    }
    .video-container {
      margin: 20px 0;
    }
    .math {
      margin-top: 20px;
      font-size: 1.2em;
    }
  </style>
</head>
<body>

  <h1>Distributed Delay Controller Optimization</h1>

  <p class="math">
    This website was created to support the Thesis 'Control by Shaping Delay Distribution' by Jasper Visterin. If you are already familiar with the matter, 
    feel free to skip to the animations illustrating a tradeoff between kernel smoothness and closed-loop plant performance, or more concretely, the regularization-spectral abscissa tradeoff.
  </p>

  <h2>Background on the Thesis Objective </h2>
 <p class="math">

Building upon the methodology in [1], a general-purpose controller optimization framework concerning the spectral abscissa is developed for systems with discrete and distributed delays.  
   In the framework, LTI time-delay systems of the form \(P\) are considered where \(x\in\mathbb{R}^n\) is the state variable, \(u\in\mathbb{R}^{n_u}\) 
   represents the control input, and \(y\in\mathbb{R}^{n_y}\) represents the control output. 
$$
P \leftrightarrow\left\{\begin{aligned}
\dot{x}(t) & =\sum_{k=1}^{m_A} A_k x\left(t-h_{A, k}\right)+\sum_{k=1}^{m_{B}} B_{k} u\left(t-h_{B, k}\right) + \int_{-h_I}^{0}G(\theta)x(t+\theta)d\theta
\\
y(t) & =\sum_{k=1}^{m_{C}} C_{ k} x\left(t-h_{C, k}\right)
\end{aligned}\right.    
$$
   
Typically, inputs correspond to system actuators steering the system to a desired state, whereas outputs are system measurements essential to know what is happening in the system. The framework allows the construction of static and dynamic output feedback controllers using the output \(y(t)\). 
   Dynamic output feedback controllers are of form \(C_{dyn}\) with \(x_c \in \mathbb{R}^{n_c}\)
   the state variable of the controller and real-valued matrices \(A_c, B_c, C_c\), and \(D_c\) with appropriate dimensions.

   $$
   \label{eq:dynamic}
C_{dyn} \leftrightarrow\left\{\begin{aligned}
\dot{x}_c(t) & =A_c x_c(t)+B_c y(t) \\
u(t) & =C_c x_c(t)+D_c y(t)
\end{aligned}\right.
$$
   
If \(n_c\) is equal to \(0\), the dynamic controller reduces to the static output feedback law as \(C_{stat}\).
$$
   \label{eq:static}
C_{stat} \leftrightarrow u(t)=D_c y(t)
$$
A novel kind of feedback, for which static feedback is a special case of the control law \(C_{dist}\) , the following control law combining static and distributed delay output feedback where \(K_1, K_2 \in \mathbb{R}^{n_u \times n_y}\), the kernel \(g(\theta)\) is defined as a Chebyshev expansion
   for a fixed positive integer \(K\), \(c_k \in \mathbb{R}\), \(T_k\) denotes the Chebyshev polynomial of the first kind of order \(k\). 
   The delay \(\tau\) is the maximum delay appearing in \(P\).
$$
    \label{eq:distributed}
C_{dist} \leftrightarrow u(t)=K_{1}\, y(t) + K_{2} \int_{-\tau}^{0} g(\theta) y(t+\theta) d \theta, \quad g(\theta)=\sum_{k=0}^K c_k T_k\left(2 \frac{\theta}{\tau}+1\right)
$$

When considering a controller \(C\) for a plant \(P\), a closed-loop feedback system is obtained. This system is denoted as \(CL\). The framework is then concerned with minimizing the spectral abscissa 
   of this closed-loop system. The spectral abcissa is the real part of the rightmost root in the spectrum of \(CL\). In other words, the optimization problem can be formulated as:

   $$
   \min _{\mathbf{p}} \max \left( \, \operatorname{Re}\left(\lambda\right) \mid \lambda \in \Lambda(CL) \,\,\right) = \min _{\mathbf{p}} \sigma_{\max} 
   $$

   Considering a static, dynamic, and static-distributed delay output feedback controller, the parameters \(\mathbf{p}\) are respectively 
   $$
\mathrm{vec}(D_c) , \quad\mathrm{vec}\left(\left[\begin{array}{cc}
B_c & A_c \\
D_c & C_c
\end{array}\right]\right) \quad\text{and} \quad \begin{bmatrix} \mathrm{vec}(K_1) \\ \mathrm{vec}(K_2) \\ c \end{bmatrix}  $$
      where \(\mathrm{vec}(\cdot)\) denotes column-wise flattening. These are the parameters \(\mathbf{p}\) considered that will be tuned in order to obtain an optimal value of the spectral abscissa.


   
  <h2> Regularization of the Kernel </h2>
 <p class="math">
   
    The main concern when naively optimizing the novel controller \(C_{dist}\) is that the kernel \(g(\theta)\) will exhibit extreme oscillations when \( K \) is chosen large. This effect has all kinds of undesired consequences. Hence,
    two approaches have been developed to deal with this. On one hand, there is a Penalty-Based Regularization which uses a Penalty-term \(REG(c)\). This Penalty-term is implemented in the following way:
    $$
   REG(c)=R[g]=\int_{-\tau}^{0}\left(g^{\prime}(\theta)\right)^2 d \theta
   $$

   The other option is a more heuristic regularization. This heuristic, which is called the Damping Heuristic, has been developed via Chebyshev approximation theory. 
   The intuition used here is that, roughly speaking, for analytic functions that are analytic on a larger domain that these functions have Chebyshev coefficients that decay faster than functions which are analytic on a smaller domain. Assuming reasonable conditions, both functions have coefficients that decay exponentially [2]. 
   Hence, to obtain smooth kernels \(g(\theta)\), this principle can be employed. The Chebyshev coefficients are damped with an exponential factor \( \rho>1 \): 
   $$
   c_k= 
\begin{cases}
\tilde{c}_k& 0\leq k \leq 5 \\
\frac{\tilde{c}_k}{\rho^{k-5}}, & 6 \leq k
\end{cases}    
   $$
   Note that this concept does not directly penalize the global smoothness, but controls the kernel's resolution to avoid overfitting or instability. It acts as a practical damping mechanism during optimization. 
   While \( \rho \) is still a hyperparameter, the concept is simple, interpretable, and rooted in Chebyshev approximation theory. 
 </p>
<h3> Multi-Objective Optimization and Regularization </h3>
  <p class="math">
    Furthermore, as regularization is applied, the spectral abscissa will always experience an increase compared to the situation where \(g(\theta)\) is not regularized. 
    It is, in fact, a multi-objective optimization problem where two objectives are optimized at once. 
    In bi-objective optimization, different linear combinations of two convex objective functions, \(J_1(\mathbf{p}) \) and \(J_2(\mathbf{p}) \), trace out the Pareto front. 
    However, for the two objectives \(\sigma_{\max}\) and \(REG(c)\), the complete objective function will be non-convex due to the presence of the spectral abscissa. 
    Hence, this visualization is only valid for a specific local minimum. In non-convex scenarios, one approach to constructing a Pareto front involves identifying a local minimum of the weighted objective for a specific \(\alpha\) value. 
    By systematically varying \(\alpha\) across a predefined grid and solving the optimization problem at each step, this method seeks to observe the evolution of the local minimum, 
    thereby approximating the local Pareto front.
    $$
 \min _{\mathbf{p}} \alpha J_1(\mathbf{p})+(1-\alpha)J_2(\mathbf{p}),\quad\alpha\in[0,1]
$$
Theory showed that constructing such a Pareto front, following the latter described process, can express discontinuous jumps between local minima due to the non-convex nature 
    of the objective [3]. Experiments confirmed that this can indeed happen.
    The purpose of this website is to show how this Pareto Front is formed using the different kinds of regularization. In the case of the Damping Heuristic, one cannot strictly speak about a bi-objective optimization because the damping is implicit, unlike \( REG(c) \).
    However, the visual of the Pareto Front can also be obtained by using damping. As you continue on this website, you will see in the provided animations of
    how the spectral abscissa changes when a regularization parameter like \( \alpha \) or \( \rho \) is changed. 

  </p>
   <h2>Animations of Experiments </h2>
  <p class="math">
    The videos below show the evolution of the spectrum as parameters are tuned for the following system:
    $$ P \leftrightarrow  \dot{x}(t) = (1-e^{-1})x(t)+\frac{1}{2}x(t-1)+\frac{e}{2}\,x(t-2)+\frac{e^2}{2} x(t-3) +\int_{-1}^{0}\theta \,x(t+\theta)d\theta  + u\left(t-\frac{1}{32}\right) $$
    For this system, illustrations of both Penalty- as Damping-regularization are given.
  </p>

    <div class="video-container">
    <video width="100%" controls>
      <source src="first_experiment.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>

    <div class="video-container">
    <video width="100%" controls>
      <source src="second_experiment.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>

      <div class="video-container">
    <video width="100%" controls>
      <source src="system_1_alpha_animation.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>

    <p class="math">
    The video below shows the evolution of the spectrum as parameters are tuned for the following system:
    $$ P \leftrightarrow   \dot{x}(t) = \left(1-e^{-1}\right)\begin{bmatrix}
1 & 2 \\
2 & 1 \\
\end{bmatrix}x(t)
+\frac{1}{2}\begin{bmatrix}
1 & 0 \\
0 & 1 \\
\end{bmatrix}x(t-1)+
\frac{e}{2}\begin{bmatrix}
-2 & 1 \\
1 & -2 \\
\end{bmatrix}x(t-2)+ \int_{-1}^{0}\begin{bmatrix}
2e^{\theta} & 0 \\
0 & e^{\theta} \\
\end{bmatrix} x(t+\theta)
 d\theta 
 +
\begin{bmatrix}
1 \\
0 \\
\end{bmatrix}u\left(t-\frac{1}{2}\right)  $$
  </p>

  <div class="video-container">
    <video width="100%" controls>
      <source src="system_2_experiment.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
  </div>



   <p class="math">
     Sources: 
   </p>
   <p class="math">
     [1] P. Appeltans, H. Silm, and W. Michiels, TDS-CONTROL: a MATLAB
package for the analysis and controller-design of time-delay systems, IFAC-
PapersOnLine, vol. 55, pp. 272â€“277, 1 2022.
   </p>
  
 <p class="math">
     [2] L. N. Trefethen, Approximation Theory and Approximation Practice, Extended Edition. 1 2019.
   </p>
  <p class="math">
     [3] K. Miettinen, Nonlinear multiobjective optimization. 1 1998.
   </p>
  
</body>
</html>
